2017-05-14 18:08:15 [scrapy.utils.log] INFO: Scrapy 1.3.3 started (bot: agg)
2017-05-14 18:08:15 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'agg', 'LOG_FILE': 'log', 'NEWSPIDER_MODULE': 'agg.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['agg.spiders']}
2017-05-14 18:08:15 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-05-14 18:08:15 [twisted] CRITICAL: Unhandled error in Deferred:
2017-05-14 18:08:15 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "c:\users\akumar\appdata\local\programs\python\python36-32\lib\site-packages\twisted\internet\defer.py", line 1301, in _inlineCallbacks
    result = g.send(result)
  File "c:\users\akumar\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\crawler.py", line 71, in crawl
    self.spider = self._create_spider(*args, **kwargs)
  File "c:\users\akumar\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\crawler.py", line 94, in _create_spider
    return self.spidercls.from_crawler(self, *args, **kwargs)
  File "c:\users\akumar\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\spiders\__init__.py", line 50, in from_crawler
    spider = cls(*args, **kwargs)
  File "C:\VM\Shared\crawler_project\crawler\agg\spiders\nature_spider.py", line 10, in __init__
    self.sync_length = int(kwargs['sync_length'])
KeyError: 'sync_length'
2017-05-14 18:08:53 [scrapy.utils.log] INFO: Scrapy 1.3.3 started (bot: agg)
2017-05-14 18:08:53 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'agg', 'LOG_FILE': 'log', 'NEWSPIDER_MODULE': 'agg.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['agg.spiders']}
2017-05-14 18:08:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-05-14 18:08:53 [twisted] CRITICAL: Unhandled error in Deferred:
2017-05-14 18:08:53 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "c:\users\akumar\appdata\local\programs\python\python36-32\lib\site-packages\twisted\internet\defer.py", line 1301, in _inlineCallbacks
    result = g.send(result)
  File "c:\users\akumar\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\crawler.py", line 72, in crawl
    self.engine = self._create_engine()
  File "c:\users\akumar\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\crawler.py", line 97, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "c:\users\akumar\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "c:\users\akumar\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "c:\users\akumar\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "c:\users\akumar\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "c:\users\akumar\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "c:\users\akumar\appdata\local\programs\python\python36-32\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 978, in _gcd_import
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load
  File "<frozen importlib._bootstrap>", line 950, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 655, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 205, in _call_with_frames_removed
  File "c:\users\akumar\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "c:\users\akumar\appdata\local\programs\python\python36-32\lib\site-packages\twisted\web\client.py", line 42, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "c:\users\akumar\appdata\local\programs\python\python36-32\lib\site-packages\twisted\internet\endpoints.py", line 37, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "c:\users\akumar\appdata\local\programs\python\python36-32\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "c:\users\akumar\appdata\local\programs\python\python36-32\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ModuleNotFoundError: No module named 'win32api'
2017-05-14 18:09:51 [scrapy.utils.log] INFO: Scrapy 1.3.3 started (bot: agg)
2017-05-14 18:09:51 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'agg', 'LOG_FILE': 'log', 'NEWSPIDER_MODULE': 'agg.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['agg.spiders']}
2017-05-14 18:09:51 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-05-14 18:09:52 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-05-14 18:09:52 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-05-14 18:09:52 [twisted] CRITICAL: Unhandled error in Deferred:
2017-05-14 18:09:52 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "c:\users\akumar\appdata\local\programs\python\python36-32\lib\site-packages\twisted\internet\defer.py", line 1301, in _inlineCallbacks
    result = g.send(result)
  File "c:\users\akumar\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\crawler.py", line 72, in crawl
    self.engine = self._create_engine()
  File "c:\users\akumar\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\crawler.py", line 97, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "c:\users\akumar\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\core\engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "c:\users\akumar\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\core\scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "c:\users\akumar\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "c:\users\akumar\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "c:\users\akumar\appdata\local\programs\python\python36-32\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "c:\users\akumar\appdata\local\programs\python\python36-32\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 978, in _gcd_import
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load
  File "<frozen importlib._bootstrap>", line 950, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 655, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 205, in _call_with_frames_removed
  File "C:\VM\Shared\crawler_project\crawler\agg\pipelines.py", line 7, in <module>
    import urllib2
ModuleNotFoundError: No module named 'urllib2'
2017-05-14 20:28:28 [scrapy.utils.log] INFO: Scrapy 1.3.3 started (bot: agg)
2017-05-14 20:28:28 [scrapy.utils.log] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'agg.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['agg.spiders'], 'LOG_FILE': 'log', 'BOT_NAME': 'agg'}
2017-05-14 20:28:28 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2017-05-14 20:28:28 [twisted] CRITICAL: Unhandled error in Deferred:
2017-05-14 20:28:28 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "c:\users\akumar\envs\scrapy_env\lib\site-packages\twisted\internet\defer.py", line 1301, in _inlineCallbacks
    result = g.send(result)
  File "c:\users\akumar\envs\scrapy_env\lib\site-packages\scrapy\crawler.py", line 90, in crawl
    six.reraise(*exc_info)
  File "c:\users\akumar\envs\scrapy_env\lib\site-packages\scrapy\crawler.py", line 72, in crawl
    self.engine = self._create_engine()
  File "c:\users\akumar\envs\scrapy_env\lib\site-packages\scrapy\crawler.py", line 97, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "c:\users\akumar\envs\scrapy_env\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "c:\users\akumar\envs\scrapy_env\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "c:\users\akumar\envs\scrapy_env\lib\site-packages\scrapy\middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "c:\users\akumar\envs\scrapy_env\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "c:\users\akumar\envs\scrapy_env\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\Lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "c:\users\akumar\envs\scrapy_env\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module>
    from twisted.web.client import ResponseFailed
  File "c:\users\akumar\envs\scrapy_env\lib\site-packages\twisted\web\client.py", line 42, in <module>
    from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
  File "c:\users\akumar\envs\scrapy_env\lib\site-packages\twisted\internet\endpoints.py", line 37, in <module>
    from twisted.internet.stdio import StandardIO, PipeAddress
  File "c:\users\akumar\envs\scrapy_env\lib\site-packages\twisted\internet\stdio.py", line 30, in <module>
    from twisted.internet import _win32stdio
  File "c:\users\akumar\envs\scrapy_env\lib\site-packages\twisted\internet\_win32stdio.py", line 9, in <module>
    import win32api
ImportError: No module named win32api
2017-05-14 20:30:24 [scrapy.utils.log] INFO: Scrapy 1.3.3 started (bot: agg)
2017-05-14 20:30:24 [scrapy.utils.log] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'agg.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['agg.spiders'], 'LOG_FILE': 'log', 'BOT_NAME': 'agg'}
2017-05-14 20:30:24 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2017-05-14 20:30:24 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-05-14 20:30:24 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-05-14 20:30:24 [twisted] CRITICAL: Unhandled error in Deferred:
2017-05-14 20:30:24 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "c:\users\akumar\envs\scrapy_env\lib\site-packages\twisted\internet\defer.py", line 1301, in _inlineCallbacks
    result = g.send(result)
  File "c:\users\akumar\envs\scrapy_env\lib\site-packages\scrapy\crawler.py", line 90, in crawl
    six.reraise(*exc_info)
  File "c:\users\akumar\envs\scrapy_env\lib\site-packages\scrapy\crawler.py", line 72, in crawl
    self.engine = self._create_engine()
  File "c:\users\akumar\envs\scrapy_env\lib\site-packages\scrapy\crawler.py", line 97, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "c:\users\akumar\envs\scrapy_env\lib\site-packages\scrapy\core\engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "c:\users\akumar\envs\scrapy_env\lib\site-packages\scrapy\core\scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "c:\users\akumar\envs\scrapy_env\lib\site-packages\scrapy\middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "c:\users\akumar\envs\scrapy_env\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "c:\users\akumar\envs\scrapy_env\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python27\Lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "C:\VM\Shared\crawler_project\crawler\agg\pipelines.py", line 14, in <module>
    import pdfkit
ImportError: No module named pdfkit
2017-05-14 20:30:44 [scrapy.utils.log] INFO: Scrapy 1.3.3 started (bot: agg)
2017-05-14 20:30:44 [scrapy.utils.log] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'agg.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['agg.spiders'], 'LOG_FILE': 'log', 'BOT_NAME': 'agg'}
2017-05-14 20:30:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2017-05-14 20:30:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-05-14 20:30:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-05-14 20:30:45 [scrapy.middleware] INFO: Enabled item pipelines:
['agg.pipelines.DownloadPDFS',
 'agg.pipelines.AggPipeline',
 'agg.pipelines.JsonPipeline']
2017-05-14 20:30:45 [scrapy.core.engine] INFO: Spider opened
2017-05-14 20:30:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-05-14 20:30:45 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2017-05-14 20:30:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.nature.com/robots.txt> (referer: None)
2017-05-14 20:30:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.nature.com/nature/archive/category.html?code=archive_news_views> (referer: None)
2017-05-14 20:30:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.nature.com/nature/journal/vaop/ncurrent/pdf/nature22493.pdf> (referer: None)
2017-05-14 20:30:46 [scrapy.pipelines.files] DEBUG: File (downloaded): Downloaded file from <GET http://www.nature.com/nature/journal/vaop/ncurrent/pdf/nature22493.pdf> referred in <None>
2017-05-14 20:30:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.nature.com/nature/journal/vaop/ncurrent/pdf/nature22494.pdf> (referer: None)
2017-05-14 20:30:46 [scrapy.pipelines.files] DEBUG: File (downloaded): Downloaded file from <GET http://www.nature.com/nature/journal/vaop/ncurrent/pdf/nature22494.pdf> referred in <None>
2017-05-14 20:30:46 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.nature.com/nature/archive/category.html?code=archive_news_views>
{'authors': [u'Manuel Serrano'],
 'date': u'10 May 2017',
 'date_created': 'Mon May 15 03:30:45 2017',
 'file_urls': [u'http://www.nature.com/nature/journal/vaop/ncurrent/pdf/nature22493.pdf'],
 'files': [{'checksum': '4e38be4c8f33786962842ee4a97b5950',
            'path': 'nature_news/8324bde8a1f9494f40d999f7146a2468fc409674.pdf',
            'url': 'http://www.nature.com/nature/journal/vaop/ncurrent/pdf/nature22493.pdf'}],
 'spider': 'nature_news',
 'tags': u'Ageing',
 'title': u'Ageing: Tools to eliminate senescent cells'}
2017-05-14 20:30:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.nature.com/nature/journal/v545/n7653/pdf/545164a.pdf> (referer: None)
2017-05-14 20:30:46 [scrapy.pipelines.files] DEBUG: File (downloaded): Downloaded file from <GET http://www.nature.com/nature/journal/v545/n7653/pdf/545164a.pdf> referred in <None>
2017-05-14 20:30:46 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.nature.com/nature/archive/category.html?code=archive_news_views>
{'authors': [u'Meritxell Huch', u'Emma L. Rawlins'],
 'date': u'10 May 2017',
 'date_created': 'Mon May 15 03:30:45 2017',
 'file_urls': [u'http://www.nature.com/nature/journal/vaop/ncurrent/pdf/nature22494.pdf'],
 'files': [{'checksum': '3735691b4e4e2e9bd666823db28f5225',
            'path': 'nature_news/c3da9ac86effb441598c3abe175012601cee299b.pdf',
            'url': 'http://www.nature.com/nature/journal/vaop/ncurrent/pdf/nature22494.pdf'}],
 'spider': 'nature_news',
 'tags': u'Cancer',
 'title': u'Cancer: Tumours build their niche'}
2017-05-14 20:30:46 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.nature.com/nature/archive/category.html?code=archive_news_views>
{'authors': [u'Wes Campbell'],
 'date': u'10 May 2017',
 'date_created': 'Mon May 15 03:30:45 2017',
 'file_urls': [u'http://www.nature.com/nature/journal/v545/n7653/pdf/545164a.pdf'],
 'files': [{'checksum': 'aad0e6bb6a23fca095b03cd82b9d5eed',
            'path': 'nature_news/7f26fe6b300ed78956c870be8bc966bee7e2fc8c.pdf',
            'url': 'http://www.nature.com/nature/journal/v545/n7653/pdf/545164a.pdf'}],
 'spider': 'nature_news',
 'tags': u'Atomic and molecular physics',
 'title': u'Quantum physics: Atomic envoy enables molecular control'}
2017-05-14 20:30:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.nature.com/nature/journal/v545/n7653/pdf/545166a.pdf> (referer: None)
2017-05-14 20:30:46 [scrapy.pipelines.files] DEBUG: File (downloaded): Downloaded file from <GET http://www.nature.com/nature/journal/v545/n7653/pdf/545166a.pdf> referred in <None>
2017-05-14 20:30:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.nature.com/nature/journal/v545/n7652/pdf/545035a.pdf> (referer: None)
2017-05-14 20:30:46 [scrapy.pipelines.files] DEBUG: File (downloaded): Downloaded file from <GET http://www.nature.com/nature/journal/v545/n7652/pdf/545035a.pdf> referred in <None>
2017-05-14 20:30:47 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.nature.com/nature/archive/category.html?code=archive_news_views>
{'authors': [u'Carolyn Penstein Ros\xe9'],
 'date': u'10 May 2017',
 'date_created': 'Mon May 15 03:30:45 2017',
 'file_urls': [u'http://www.nature.com/nature/journal/v545/n7653/pdf/545166a.pdf'],
 'files': [{'checksum': 'dc611afb4d2546d996a4b99ffab47111',
            'path': 'nature_news/574c88ca578ab52722733a080c6486f6ae1ba036.pdf',
            'url': 'http://www.nature.com/nature/journal/v545/n7653/pdf/545166a.pdf'}],
 'spider': 'nature_news',
 'tags': u'Computer science',
 'title': u'Artificial intelligence: A social spin on language analysis'}
2017-05-14 20:30:47 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.nature.com/nature/archive/category.html?code=archive_news_views>
{'authors': [u'Matthew Gaunt', u'Patrick Williamson'],
 'date': u'03 May 2017',
 'date_created': 'Mon May 15 03:30:45 2017',
 'file_urls': [u'http://www.nature.com/nature/journal/v545/n7652/pdf/545035a.pdf'],
 'files': [{'checksum': '8536f77e4fd8851d7ee6e3948b1ffda7',
            'path': 'nature_news/e2a272637b7b13745af120a49d15d61ada190add.pdf',
            'url': 'http://www.nature.com/nature/journal/v545/n7652/pdf/545035a.pdf'}],
 'spider': 'nature_news',
 'tags': u'Chemistry',
 'title': u'Organic chemistry: Nickel steps towards selectivity'}
2017-05-14 20:30:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.nature.com/nature/journal/v545/n7652/pdf/545032a.pdf> (referer: None)
2017-05-14 20:30:47 [scrapy.pipelines.files] DEBUG: File (downloaded): Downloaded file from <GET http://www.nature.com/nature/journal/v545/n7652/pdf/545032a.pdf> referred in <None>
2017-05-14 20:30:47 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.nature.com/nature/archive/category.html?code=archive_news_views>
{'authors': [u'Jared Diamond'],
 'date': u'03 May 2017',
 'date_created': 'Mon May 15 03:30:45 2017',
 'file_urls': [u'http://www.nature.com/nature/journal/v545/n7652/pdf/545032a.pdf'],
 'files': [{'checksum': '21500016745417732625b38319630900',
            'path': 'nature_news/aada49f6809b9831117a452be3bc10c44ccd2c92.pdf',
            'url': 'http://www.nature.com/nature/journal/v545/n7652/pdf/545032a.pdf'}],
 'spider': 'nature_news',
 'tags': u'Anthropology',
 'title': u'Archaeology: Of rats and resilience'}
2017-05-14 20:30:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.nature.com/nature/journal/v545/n7652/pdf/545039b.pdf> (referer: None)
2017-05-14 20:30:47 [scrapy.pipelines.files] DEBUG: File (downloaded): Downloaded file from <GET http://www.nature.com/nature/journal/v545/n7652/pdf/545039b.pdf> referred in <None>
2017-05-14 20:30:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.nature.com/nature/journal/v545/n7653/pdf/545161a.pdf> (referer: None)
2017-05-14 20:30:47 [scrapy.pipelines.files] DEBUG: File (downloaded): Downloaded file from <GET http://www.nature.com/nature/journal/v545/n7653/pdf/545161a.pdf> referred in <None>
2017-05-14 20:30:47 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.nature.com/nature/archive/category.html?code=archive_news_views>
{'authors': '',
 'date': u'03 May 2017',
 'date_created': 'Mon May 15 03:30:45 2017',
 'file_urls': [u'http://www.nature.com/nature/journal/v545/n7652/pdf/545039b.pdf'],
 'files': [{'checksum': 'f094010025a5ed349d3fbfc034fa8933',
            'path': 'nature_news/5807af32e57b61b53a30d60d1e6b8638f2a57564.pdf',
            'url': 'http://www.nature.com/nature/journal/v545/n7652/pdf/545039b.pdf'}],
 'spider': 'nature_news',
 'tags': u'Cell biology',
 'title': u'50 & 100 Years Ago'}
2017-05-14 20:30:47 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.nature.com/nature/archive/category.html?code=archive_news_views>
{'authors': [u'Tobias Bolch'],
 'date': u'10 May 2017',
 'date_created': 'Mon May 15 03:30:45 2017',
 'file_urls': [u'http://www.nature.com/nature/journal/v545/n7653/pdf/545161a.pdf'],
 'files': [{'checksum': 'a1abcd66667dc7f8b6a02ed2b5586659',
            'path': 'nature_news/5782adf29a6ea2bbab7bd651911bc7362b0bcc54.pdf',
            'url': 'http://www.nature.com/nature/journal/v545/n7653/pdf/545161a.pdf'}],
 'spider': 'nature_news',
 'tags': u'Hydrology',
 'title': u'Hydrology: Asian glaciers are a reliable water source'}
2017-05-14 20:30:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.nature.com/nature/journal/v545/n7652/pdf/545037a.pdf> (referer: None)
2017-05-14 20:30:47 [scrapy.pipelines.files] DEBUG: File (downloaded): Downloaded file from <GET http://www.nature.com/nature/journal/v545/n7652/pdf/545037a.pdf> referred in <None>
2017-05-14 20:30:47 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.nature.com/nature/archive/category.html?code=archive_news_views>
{'authors': [u'James S. Risbey', u'Stephan Lewandowsky'],
 'date': u'03 May 2017',
 'date_created': 'Mon May 15 03:30:45 2017',
 'file_urls': [u'http://www.nature.com/nature/journal/v545/n7652/pdf/545037a.pdf'],
 'files': [{'checksum': '3936f6e71a6f05c29f12225afeec6b42',
            'path': 'nature_news/7c5aaf9454da54d0e21f83168c467024759c230b.pdf',
            'url': 'http://www.nature.com/nature/journal/v545/n7652/pdf/545037a.pdf'}],
 'spider': 'nature_news',
 'tags': u'Climate change',
 'title': u"Climate science: The 'pause' unpacked"}
2017-05-14 20:30:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.nature.com/nature/archive/category.html?code=archive_news_views&year=2017&month=04> (referer: http://www.nature.com/nature/archive/category.html?code=archive_news_views)
2017-05-14 20:30:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.nature.com/nature/journal/vaop/ncurrent/pdf/nature22491.pdf> (referer: None)
2017-05-14 20:30:47 [scrapy.pipelines.files] DEBUG: File (downloaded): Downloaded file from <GET http://www.nature.com/nature/journal/vaop/ncurrent/pdf/nature22491.pdf> referred in <None>
2017-05-14 20:30:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.nature.com/nature/journal/v545/n7652/pdf/545039a.pdf> (referer: None)
2017-05-14 20:30:47 [scrapy.pipelines.files] DEBUG: File (downloaded): Downloaded file from <GET http://www.nature.com/nature/journal/v545/n7652/pdf/545039a.pdf> referred in <None>
2017-05-14 20:30:48 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.nature.com/nature/archive/category.html?code=archive_news_views>
{'authors': [u'Ching-Ju Tsai', u'Joerg Standfuss', u'Robert M. Glaeser'],
 'date': u'03 May 2017',
 'date_created': 'Mon May 15 03:30:45 2017',
 'file_urls': [u'http://www.nature.com/nature/journal/vaop/ncurrent/pdf/nature22491.pdf'],
 'files': [{'checksum': '153587bbe118ba22767047dfe06878d6',
            'path': 'nature_news/aa9f7a381f75d32e4e673e5f1e1fac457c196df7.pdf',
            'url': 'http://www.nature.com/nature/journal/vaop/ncurrent/pdf/nature22491.pdf'}],
 'spider': 'nature_news',
 'tags': u'Microscopy',
 'title': u'Structural biology: Signalling under the microscope'}
2017-05-14 20:30:48 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.nature.com/nature/archive/category.html?code=archive_news_views>
{'authors': [u'J. Gray Camp', u'Barbara Treutlein'],
 'date': u'03 May 2017',
 'date_created': 'Mon May 15 03:30:45 2017',
 'file_urls': [u'http://www.nature.com/nature/journal/v545/n7652/pdf/545039a.pdf'],
 'files': [{'checksum': '4952362f999405cbcfc735a12f03c719',
            'path': 'nature_news/018e5f7fddacb44e638936e77dfb36758dacfa27.pdf',
            'url': 'http://www.nature.com/nature/journal/v545/n7652/pdf/545039a.pdf'}],
 'spider': 'nature_news',
 'tags': u'Biological techniques',
 'title': u'Human development: Advances in mini-brain technology'}
2017-05-14 20:30:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.nature.com/nature/journal/v545/n7653/pdf/nature22492.pdf> (referer: None)
2017-05-14 20:30:52 [scrapy.pipelines.files] DEBUG: File (downloaded): Downloaded file from <GET http://www.nature.com/nature/journal/v545/n7653/pdf/nature22492.pdf> referred in <None>
2017-05-14 20:30:52 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.nature.com/nature/archive/category.html?code=archive_news_views>
{'authors': [u'Kathleen J. Sweadner'],
 'date': u'03 May 2017',
 'date_created': 'Mon May 15 03:30:45 2017',
 'file_urls': [u'http://www.nature.com/nature/journal/v545/n7653/pdf/nature22492.pdf'],
 'files': [{'checksum': '36076793b1e279823fbd32c24a0e2663',
            'path': 'nature_news/72f4d72ca3ebaf9536e3c9f1558c66a20515bb5f.pdf',
            'url': 'http://www.nature.com/nature/journal/v545/n7653/pdf/nature22492.pdf'}],
 'spider': 'nature_news',
 'tags': u'Biophysics',
 'title': u'Structural biology: An ion-transport enzyme that rocks'}
2017-05-14 20:30:52 [scrapy.core.engine] INFO: Closing spider (finished)
2017-05-14 20:30:52 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 5671,
 'downloader/request_count': 15,
 'downloader/request_method_count/GET': 15,
 'downloader/response_bytes': 5773470,
 'downloader/response_count': 15,
 'downloader/response_status_count/200': 15,
 'file_count': 12,
 'file_status_count/downloaded': 12,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 5, 15, 3, 30, 52, 309000),
 'item_scraped_count': 12,
 'log_count/DEBUG': 40,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 15,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2017, 5, 15, 3, 30, 45, 15000)}
2017-05-14 20:30:52 [scrapy.core.engine] INFO: Spider closed (finished)
